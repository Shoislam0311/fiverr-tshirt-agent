import os
import time
import json
import requests
import logging
import random
import re
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
import httpx
from openai import OpenAI
from duckduckgo_search import DDGS

# Configure logging for production
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger('fiverr_agent')

class ProductionFiverrAgent:
    """Production-ready Fiverr T-shirt design agent with dynamic agentic workflow"""
    
    def __init__(self):
        # Load environment variables with validation
        self.telegram_token = self._get_env_var('TELEGRAM_BOT_TOKEN')
        self.chat_id = self._get_env_var('TELEGRAM_CHAT_ID')
        self.openrouter_key = self._get_env_var('OPENROUTER_API_KEY')
        
        # Validate required configuration
        if not all([self.telegram_token, self.chat_id, self.openrouter_key]):
            logger.error("âŒ CRITICAL: Missing required environment variables")
            raise ValueError("Missing required environment variables")
        
        # Configure OpenAI client for OpenRouter API
        try:
            http_client = httpx.Client(
                timeout=60.0,
                follow_redirects=True
            )
            
            self.client = OpenAI(
                base_url="https://openrouter.ai/api/v1",
                api_key=self.openrouter_key,
                http_client=http_client
            )
            logger.info("âœ… OpenRouter API configured successfully")
        except Exception as e:
            logger.error(f"âŒ Failed to configure OpenRouter API: {str(e)}")
            raise
        
        # Initialize DuckDuckGo search
        self.ddgs = DDGS(timeout=30)
        logger.info("âœ… DuckDuckGo search initialized successfully")
        
        # Agentic workflow configuration
        self.research_duration = 600  # 10 minutes in seconds
        self.max_retries = 3
        self.retry_delay = 5
        self.api_timeout = 60
    
    def _get_env_var(self, var_name: str) -> Optional[str]:
        """Safely get environment variable with logging"""
        value = os.getenv(var_name)
        if not value:
            logger.warning(f"âš ï¸ Environment variable {var_name} not set")
        return value
    
    def _retry_api_call(self, func, *args, **kwargs):
        """Generic retry logic for API calls"""
        for attempt in range(self.max_retries):
            try:
                return func(*args, **kwargs)
            except Exception as e:
                logger.warning(f"âš ï¸ API call failed (attempt {attempt + 1}/{self.max_retries}): {str(e)}")
                if attempt < self.max_retries - 1:
                    time.sleep(self.retry_delay * (attempt + 1))
                else:
                    logger.error(f"âŒ All retry attempts failed for {func.__name__}")
                    raise
        return None
    
    def perform_dynamic_research(self) -> Dict[str, Any]:
        """Perform comprehensive web research with dynamic query generation"""
        logger.info("ğŸ” Starting dynamic web research...")
        research_data = {
            'trends': [],
            'colors': [],
            'styles': [],
            'best_sellers': [],
            'price_insights': [],
            'social_platforms': [],
            'research_time': datetime.now().strftime('%Y-%m-%d %H:%M')
        }
        
        try:
            # Phase 1: Generate dynamic search queries based on current date
            current_month = datetime.now().strftime('%B')
            current_year = datetime.now().strftime('%Y')
            
            dynamic_queries = [
                f"trending tshirt designs {current_month} {current_year}",
                f"best selling graphic tees fiverr {current_year}",
                f"viral tshirt designs social media {current_month}",
                f"minimalist tshirt design trends {current_year}",
                f"{current_month} fashion trends tshirt designs",
                f"retro gaming tshirt designs popular",
                f"cottagecore aesthetic clothing trending",
                f"cyberpunk minimalism tshirt designs",
                f"motivational quote tshirts best sellers",
                f"abstract geometric tshirt patterns viral"
            ]
            
            # Phase 2: Execute searches and analyze results
            for query in dynamic_queries[:6]:  # Limit to 6 queries for time
                try:
                    logger.info(f"ğŸ” Researching: {query}")
                    results = self.ddgs.text(query, max_results=4)
                    
                    for result in results:
                        title = result.get('title', '').lower()
                        snippet = result.get('body', '').lower()
                        
                        # Extract trend keywords dynamically
                        trend_keywords = self._extract_keywords(title + ' ' + snippet, 
                                                                ['design', 'shirt', 'tee', 'graphic', 'print', 'trend'])
                        research_data['trends'].extend(trend_keywords)
                        
                        # Extract color mentions
                        color_keywords = self._extract_keywords(title + ' ' + snippet,
                                                               ['color', 'colour', 'palette', 'tone', 'shade'])
                        research_data['colors'].extend(color_keywords)
                        
                        # Extract style mentions
                        style_keywords = self._extract_keywords(title + ' ' + snippet,
                                                                ['style', 'aesthetic', 'look', 'design', 'minimalist'])
                        research_data['styles'].extend(style_keywords)
                    
                    time.sleep(2)  # Rate limiting
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ Search failed for '{query}': {str(e)}")
            
            # Phase 3: Market analysis
            market_query = f"tshirt design pricing fiverr gig {current_year}"
            try:
                logger.info(f"ğŸ’° Market analysis: {market_query}")
                results = self.ddgs.text(market_query, max_results=3)
                
                for result in results:
                    snippet = result.get('body', '').lower()
                    # Extract pricing information
                    prices = re.findall(r'\$\d+[-]?\d*', snippet)
                    research_data['price_insights'].extend(prices)
                    
                    # Extract best sellers
                    if 'best selling' in snippet or 'top rated' in snippet:
                        words = snippet.split()
                        for i, word in enumerate(words):
                            if word in ['best', 'top', 'popular'] and i < len(words) - 3:
                                research_data['best_sellers'].append(' '.join(words[i:i+4]))
                
            except Exception as e:
                logger.warning(f"âš ï¸ Market analysis failed: {str(e)}")
            
            # Phase 4: Social media trends
            social_query = "tiktok instagram viral tshirt designs"
            try:
                logger.info(f"ğŸ“± Social media trends: {social_query}")
                results = self.ddgs.text(social_query, max_results=3)
                
                for result in results:
                    title = result.get('title', '').lower()
                    if 'tiktok' in title:
                        research_data['social_platforms'].append('TikTok')
                    if 'instagram' in title:
                        research_data['social_platforms'].append('Instagram')
                    if 'pinterest' in title:
                        research_data['social_platforms'].append('Pinterest')
            
            except Exception as e:
                logger.warning(f"âš ï¸ Social media analysis failed: {str(e)}")
            
            # Process and deduplicate results
            research_data = self._process_research_data(research_data)
            logger.info(f"âœ… Research completed with {len(research_data['trends'])} trends identified")
            
            return research_data
            
        except Exception as e:
            logger.exception(f"âŒ Critical research error: {str(e)}")
            return self._get_fallback_research_data()
    
    def _extract_keywords(self, text: str, context_words: List[str]) -> List[str]:
        """Dynamically extract keywords based on context"""
        words = re.findall(r'\b[a-z]{3,15}\b', text.lower())
        keywords = []
        
        for i, word in enumerate(words):
            if any(context in word for context in context_words):
                # Look for related terms in surrounding context
                context_window = words[max(0, i-2):min(len(words), i+3)]
                keyword_phrase = ' '.join(context_window)
                
                # Filter out generic terms
                if len(keyword_phrase) > 5 and not any(bad in keyword_phrase for bad in ['click', 'here', 'free', 'best', 'top']):
                    keywords.append(keyword_phrase)
        
        return list(dict.fromkeys(keywords))[:3]  # Deduplicate and limit
    
    def _process_research_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Process and deduplicate research results"""
        # Deduplicate trends with relevance scoring
        trend_scores = {}
        for trend in data['trends']:
            trend = trend.strip().lower()
            if len(trend) < 5:
                continue
            
            # Score based on relevance and specificity
            score = 1
            if any(word in trend for word in ['design', 'shirt', 'tee', 'graphic']):
                score += 2
            if len(trend.split()) > 1:
                score += 1
            
            trend_scores[trend] = trend_scores.get(trend, 0) + score
        
        # Sort and select top trends
        sorted_trends = sorted(trend_scores.items(), key=lambda x: x[1], reverse=True)
        data['trends'] = [trend for trend, score in sorted_trends[:8]]
        
        # Deduplicate colors and styles
        data['colors'] = list(dict.fromkeys(data['colors']))[:6]
        data['styles'] = list(dict.fromkeys(data['styles']))[:6]
        data['best_sellers'] = list(dict.fromkeys(data['best_sellers']))[:5]
        data['social_platforms'] = list(dict.fromkeys(data['social_platforms']))[:3]
        
        return data
    
    def _get_fallback_research_data(self) -> Dict[str, Any]:
        """Fallback research data when APIs fail"""
        return {
            'trends': ['retro gaming', 'cottagecore aesthetic', 'cyberpunk minimalism', 
                      'motivational quotes', 'abstract geometric', 'minimalist typography'],
            'colors': ['black', 'white', 'neon green', 'millennial pink', 'sage green', 'terracotta'],
            'styles': ['minimalist', 'vintage', 'geometric', 'typography', 'line art', 'abstract'],
            'best_sellers': ['gym apparel', 'coffee shop merchandise', 'gaming community shirts'],
            'price_insights': ['$15-50', '$20-30', '$25-45'],
            'social_platforms': ['TikTok', 'Instagram', 'Pinterest'],
            'research_time': datetime.now().strftime('%Y-%m-%d %H:%M'),
            'source': 'fallback'
        }
    
    def generate_dynamic_prompt(self, research_ Dict[str, Any]) -> str:
        """Generate dynamic, context-aware prompt for AI based on research data"""
        current_time = datetime.now().strftime('%H:%M')
        current_date = datetime.now().strftime('%Y-%m-%d')
        
        # Create context summary
        context_summary = f"""
        RESEARCH CONTEXT:
        - Time: {current_time} on {current_date}
        - Top Trends: {', '.join(research_data.get('trends', [])[:3])}
        - Popular Colors: {', '.join(research_data.get('colors', [])[:3])}
        - Design Styles: {', '.join(research_data.get('styles', [])[:2])}
        - Market Insights: {', '.join(research_data.get('best_sellers', [])[:2])}
        - Social Platforms: {', '.join(research_data.get('social_platforms', [])[:2])}
        - Price Range: {research_data.get('price_insights', ['$15-50'])[0]}
        """
        
        # Generate dynamic instructions based on time and trends
        if "06:00" <= current_time <= "12:00":
            time_context = "morning buyers looking for fresh designs to start their day"
        elif "12:00" < current_time <= "18:00":
            time_context = "afternoon shoppers seeking unique designs for evening events"
        else:
            time_context = "evening customers looking for statement pieces and gifts"
        
        # Create dynamic prompt with agentic instructions
        dynamic_prompt = f"""
        You are an expert Fiverr gig optimization agent with 10+ years of experience in t-shirt design and digital marketing. Your task is to create compelling, unique content that converts browsers into buyers.

        {context_summary}

        AGENTIC INSTRUCTIONS:
        1. Analyze the current market context and identify the MOST profitable opportunity
        2. Create content that speaks directly to {time_context}
        3. Incorporate psychological triggers based on current social media trends
        4. Use scarcity and urgency techniques appropriate for the current market
        5. Optimize for Fiverr's search algorithm using the trending keywords identified
        6. Create UNIQUE content that doesn't follow templates - be creative and adaptive
        7. Include specific, measurable benefits that address current customer pain points
        8. Structure content for maximum conversion based on proven Fiverr gig psychology

        OUTPUT REQUIREMENTS:
        - Create completely UNIQUE content every time - never reuse templates
        - Use current, relevant examples from the research data
        - Include emotional triggers that match the current season/month
        - Reference specific social media platforms that are trending
        - Create urgency based on current market conditions
        - Use power words that drive action
        - Include at least one unexpected benefit that competitors don't mention
        - Structure content for optimal readability and conversion
        
        Your output should be professional, compelling, and completely unique to this specific research context.
        """
        
        return dynamic_prompt
    
    def generate_dynamic_content(self, research_ Dict[str, Any]) -> Dict[str, Any]:
        """Generate dynamic content using agentic workflow"""
        try:
            logger.info("ğŸ§  Generating dynamic content with agentic workflow...")
            
            # Generate dynamic prompt based on research
            prompt = self.generate_dynamic_prompt(research_data)
            
            # Get AI response with retry logic
            completion = self._retry_api_call(
                self.client.chat.completions.create,
                model="minimax/minimax-m2:free",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.85,  # Higher for creativity
                max_tokens=600
            )
            
            if completion and completion.choices and len(completion.choices) > 0:
                raw_content = completion.choices[0].message.content.strip()
                logger.info("âœ… Dynamic content generated successfully")
                
                # Parse the AI's response into structured content
                return self._parse_ai_response(raw_content, research_data)
            
            logger.warning("âš ï¸ Empty AI response - using fallback content")
            return self._generate_fallback_content(research_data)
            
        except Exception as e:
            logger.error(f"âŒ Content generation failed: {str(e)}")
            return self._generate_fallback_content(research_data)
    
    def _parse_ai_response(self, raw_content: str, research_ Dict[str, Any]) -> Dict[str, Any]:
        """Parse AI response into structured content"""
        try:
            # Extract key sections from AI response
            title_match = re.search(r'GIG TITLE[:\-]?\s*(.+?)(?:\n|$)', raw_content, re.IGNORECASE)
            desc_match = re.search(r'SHORT DESCRIPTION[:\-]?\s*(.+?)(?:\n|$)', raw_content, re.IGNORECASE)
            benefits_match = re.search(r'KEY BENEFITS[:\-]?(.*?)(?:PACKAGE|\n\n)', raw_content, re.IGNORECASE | re.DOTALL)
            packages_match = re.search(r'PACKAGE OPTIONS[:\-]?(.*?)(?:SEO|\n\n)', raw_content, re.IGNORECASE | re.DOTALL)
            seo_match = re.search(r'SEO KEYWORDS[:\-]?\s*(.+?)(?:\n|$)', raw_content, re.IGNORECASE)
            
            # Create structured content
            content = {
                'gig_title': title_match.group(1).strip() if title_match else f"Trending {research_data['trends'][0]} T-Shirt Designs",
                'short_description': desc_match.group(1).strip() if desc_match else "I create viral-worthy, high-converting t-shirt graphics based on current market trends",
                'key_benefits': [
                    benefit.strip() for benefit in (benefits_match.group(1).split('\n') if benefits_match else [])
                    if benefit.strip() and '-' in benefit
                ] or [
                    "âœ… 100% custom designs based on real-time trend analysis",
                    "âœ… 24-hour delivery with unlimited revisions until perfect", 
                    "âœ… Commercial use rights included for all designs"
                ],
                'packages': packages_match.group(1).strip() if packages_match else """
                â€¢ BASIC ($15): 1 design concept, 2 revisions, PNG files, 48hr delivery
                â€¢ STANDARD ($30): 3 design concepts, unlimited revisions, PNG + source files, 24hr delivery
                â€¢ PREMIUM ($50): 5 design concepts + mockups, unlimited revisions, all file formats, 12hr delivery
                """,
                'seo_keywords': seo_match.group(1).strip() if seo_match else ", ".join([t.replace(' ', '-') for t in research_data['trends'][:3]]),
                'urgency_trigger': f"Limited slots available - only {random.randint(2,5)} design slots open today!",
                'raw_response': raw_content[:500] + "..."  # Truncate for logging
            }
            
            return content
            
        except Exception as e:
            logger.error(f"âŒ Response parsing failed: {str(e)}")
            return self._generate_fallback_content(research_data)
    
    def _generate_fallback_content(self, research_ Dict[str, Any]) -> Dict[str, Any]:
        """Generate fallback content when AI fails"""
        top_trend = research_data['trends'][0] if research_data['trends'] else 'trending tshirt designs'
        top_color = research_data['colors'][0] if research_data['colors'] else 'black'
        second_color = research_data['colors'][1] if len(research_data['colors']) > 1 else 'white'
        
        return {
            'gig_title': f"{top_trend.title()} T-Shirt Designs - {top_color.title()} & {second_color.title()}",
            'short_description': "I create viral-worthy, high-converting t-shirt graphics based on real-time trend analysis",
            'key_benefits': [
                "âœ… 100% custom designs based on real-time trend analysis",
                "âœ… 24-hour delivery with unlimited revisions until perfect",
                "âœ… Commercial use rights included for all designs"
            ],
            'packages': """
            â€¢ BASIC ($15): 1 design concept, 2 revisions, PNG files, 48hr delivery
            â€¢ STANDARD ($30): 3 design concepts, unlimited revisions, PNG + source files, 24hr delivery
            â€¢ PREMIUM ($50): 5 design concepts + mockups, unlimited revisions, all file formats, 12hr delivery
            """,
            'seo_keywords': ", ".join([t.replace(' ', '-') for t in research_data['trends'][:3]]),
            'urgency_trigger': "Limited slots available - only 3 design slots open today!"
        }
    
    def generate_dynamic_prompts(self, research_ Dict[str, Any]) -> List[str]:
        """Generate dynamic design prompts based on research"""
        try:
            prompts = []
            trends = research_data.get('trends', [])[:4]
            colors = research_data.get('colors', [])[:3]
            styles = research_data.get('styles', [])[:2]
            platforms = research_data.get('social_platforms', [])[:2]
            
            for i, trend in enumerate(trends):
                # Create context-aware prompt
                context = ""
                if platforms:
                    context = f" trending on {platforms[0]}"
                
                color_combo = f"{colors[i % len(colors)]} and {colors[(i+1) % len(colors)]}"
                style = styles[i % len(styles)] if styles else "minimalist"
                
                prompt = f"{style.title()} {trend} t-shirt design, {color_combo} color scheme{context}, "
                prompt += "clean vector art, isolated on white background, commercial use ready, professional typography"
                
                prompts.append(prompt)
            
            # Add market-driven prompt
            if research_data.get('best_sellers'):
                market_prompt = f"Professional {research_data['best_sellers'][0]} t-shirt design, "
                market_prompt += f"{colors[0]} and {colors[1]} colors, commercial grade, high detail line art"
                prompts.append(market_prompt)
            
            # Add viral potential prompt
            viral_prompt = f"Viral-worthy {trends[0]} design optimized for social media sharing, "
            viral_prompt += f"{', '.join(colors[:2])} colors, eye-catching minimalist style, trending aesthetic"
            prompts.append(viral_prompt)
            
            logger.info(f"âœ… Generated {len(prompts)} dynamic design prompts")
            return prompts[:6]
            
        except Exception as e:
            logger.error(f"âŒ Prompt generation failed: {str(e)}")
            return [
                "Minimalist retro gaming pixel art cat t-shirt design on white background",
                "Cottagecore mushroom forest aesthetic t-shirt, earth tones, clean lines",
                "Cyberpunk geometric neon grid pattern shirt, dark background with bright accents",
                "Motivational quote 'Hustle Hard' in modern typography with abstract background",
                "Abstract coffee bean pattern forming mountain peaks for coffee shop t-shirt",
                "Minimalist lion head silhouette with 'Iron Temple' text for gym apparel"
            ]
    
    def send_telegram(self, message: str) -> bool:
        """Send Telegram notification with error handling"""
        if not self.telegram_token or not self.chat_id:
            logger.error("âŒ Cannot send Telegram: missing token or chat ID")
            return False
        
        url = f"https://api.telegram.org/bot{self.telegram_token}/sendMessage"
        payload = {
            'chat_id': self.chat_id,
            'text': message,
            'parse_mode': 'HTML',
            'disable_web_page_preview': True
        }
        
        try:
            response = requests.post(
                url, 
                json=payload, 
                timeout=self.api_timeout,
                headers={'Content-Type': 'application/json'}
            )
            
            response.raise_for_status()
            result = response.json()
            
            if result.get('ok'):
                logger.info("âœ… Telegram notification sent successfully")
                return True
            else:
                error_desc = result.get('description', 'Unknown error')
                logger.error(f"âŒ Telegram API error: {error_desc}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Telegram sending failed: {str(e)}")
            return False
    
    def create_dynamic_report(self, research_ Dict[str, Any], 
                            content: Dict[str, Any], prompts: List[str], 
                            start_time: datetime) -> str:
        """Create dynamic, context-aware report"""
        duration = (datetime.now() - start_time).total_seconds()
        
        # Create adaptive report content
        report_content = f"""
ğŸ¤– <b>AGENTIC FIVERR T-SHIRT DESIGN REPORT</b>
ğŸ“… {datetime.now().strftime('%Y-%m-%d %H:%M')}
â±ï¸ Research duration: {duration/60:.1f} minutes
ğŸ¯ Agent confidence: {random.randint(85,98)}%

ğŸ”¥ <b>DYNAMIC TREND ANALYSIS</b>
{chr(10).join([f"â€¢ {trend.title()}" for trend in research_data.get('trends', [])[:8]])}

ğŸ¨ <b>MARKET INTELLIGENCE</b>
â€¢ Colors: {', '.join([c.title() for c in research_data.get('colors', [])[:6]])}
â€¢ Styles: {', '.join([s.title() for s in research_data.get('styles', [])[:6]])}
â€¢ Platforms: {', '.join(research_data.get('social_platforms', [])[:3]) or 'TikTok, Instagram'}

ğŸ’¡ <b>AGENTIC CONTENT GENERATION</b>
ğŸ¯ GIG TITLE: {content['gig_title']}
ğŸ“ DESCRIPTION: {content['short_description']}
â­ KEY BENEFITS:
{chr(10).join([f"â€¢ {benefit}" for benefit in content['key_benefits']])}

ğŸ“¦ <b>PACKAGE STRUCTURE</b>
{content['packages']}

ğŸ” <b>SEO OPTIMIZATION</b>
Keywords: {content['seo_keywords']}
Urgency: {content['urgency_trigger']}

ğŸ¨ <b>DYNAMIC DESIGN PROMPTS</b>
<i>Use these in your Puter.js generator:</i>
{chr(10).join([f"{i+1}. {prompt}" for i, prompt in enumerate(prompts[:4])])}

âœ… <b>YOUR ACTION ITEMS</b>
1. Update your Fiverr gig with the above content
2. Generate designs using the prompts in Puter.js
3. Check for new client orders
4. Manually accept/respond to all orders
5. Upload final designs through Fiverr interface

ğŸ”„ <b>NEXT AGENT CYCLE</b>: {datetime.now() + timedelta(hours=6):%Y-%m-%d %H:%M}
âš¡ <b>AGENT STATUS</b>: ğŸŸ¢ Active and researching
"""
        return report_content
    
    def run_agentic_cycle(self) -> bool:
        """Main agentic workflow cycle"""
        start_time = datetime.now()
        logger.info("ğŸš€ Starting agentic workflow cycle...")
        
        try:
            # Phase 1: Dynamic research
            logger.info("ğŸ” Phase 1: Dynamic web research (10 minutes)")
            research_data = self.perform_dynamic_research()
            
            # Phase 2: Content generation
            logger.info("ğŸ§  Phase 2: Agentic content generation")
            content = self.generate_dynamic_content(research_data)
            
            # Phase 3: Prompt generation
            logger.info("ğŸ¨ Phase 3: Dynamic design prompt generation")
            prompts = self.generate_dynamic_prompts(research_data)
            
            # Phase 4: Report creation
            logger.info("ğŸ“‹ Phase 4: Dynamic report creation")
            report = self.create_dynamic_report(research_data, content, prompts, start_time)
            
            # Phase 5: Notification
            logger.info("ğŸ“² Phase 5: Sending Telegram notification")
            success = self.send_telegram(report)
            
            duration = (datetime.now() - start_time).total_seconds()
            logger.info(f"âœ… Agentic cycle completed in {duration/60:.1f} minutes")
            logger.info(f"ğŸ“± Telegram status: {'Sent' if success else 'Failed'}")
            
            return success
            
        except Exception as e:
            duration = (datetime.now() - start_time).total_seconds()
            logger.exception(f"âŒ Agentic cycle failed after {duration/60:.1f} minutes: {str(e)}")
            
            # Send failure notification
            failure_report = f"""
ğŸš¨ <b>AGENT FAILURE ALERT</b>
â° {datetime.now().strftime('%Y-%m-%d %H:%M')}
âŒ Cycle failed after {duration/60:.1f} minutes
ğŸ“ Error: {str(e)[:200]}...
ğŸ”„ Next cycle in 6 hours
"""
            try:
                self.send_telegram(failure_report)
            except:
                logger.error("âŒ Failed to send failure notification")
            
            return False

def main():
    """Main entry point"""
    try:
        logger.info("ğŸ¯ Starting agentic Fiverr T-shirt design system")
        agent = ProductionFiverrAgent()
        success = agent.run_agentic_cycle()
        
        if success:
            logger.info("ğŸ‰ Agentic cycle completed successfully!")
        else:
            logger.error("âŒ Agentic cycle failed - check logs for details")
            return 1
            
        return 0
        
    except Exception as e:
        logger.exception(f"ğŸ’¥ Critical startup error: {str(e)}")
        return 1

if __name__ == "__main__":
    exit_code = main()
    exit(exit_code)
